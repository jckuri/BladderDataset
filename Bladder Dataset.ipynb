{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acute Inflammations\n",
    "**SOURCE: https://archive.ics.uci.edu/ml/datasets/Acute+Inflammations**\n",
    "\n",
    "**Abstract:** The data was created by a medical expert as a data set to test \n",
    "the expert system, which will perform the presumptive diagnosis of two \n",
    "diseases of the urinary system.\n",
    "\t\n",
    "----------------------------------------------------------------------------\n",
    "\n",
    "Data Set Characteristics:  Multivariate<br/>\n",
    "Attribute Characteristics: Categorical, Integer<br/>\n",
    "Associated Tasks: Classification<br/>\n",
    "Number of Instances: 120<br/>\n",
    "Number of Attributes: 6<br/>\n",
    "Missing Values? No<br/>\n",
    "Area: Life<br/>\n",
    "Date Donated: 2009-02-11<br/>\n",
    "\n",
    "----------------------------------------------------------------------------\n",
    "\n",
    "## Source:\n",
    "\n",
    "Jacek Czerniak, Ph.D., Assistant Professor<br/>\n",
    "Systems Research Institute<br/>\n",
    "Polish Academy of Sciences<br/>\n",
    "Laboratory of Intelligent Systems<br/>\n",
    "ul. Newelska 6, Room 218<br/>\n",
    "01-447 Warszawa, Poland<br/>\n",
    "e-mail: jacek.czerniak 'at' ibspan.waw.pl or jczerniak 'at' ukw.edu.pl <br/>\n",
    "\n",
    "----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "## Data Set Information:\n",
    "\n",
    "The main idea of this data set is to prepare the algorithm of the expert \n",
    "system, which will perform the presumptive diagnosis of two diseases of \n",
    "urinary system. It will be the example of diagnosing of the acute \n",
    "inflammations of urinary bladder and acute nephritises. For better \n",
    "understanding of the problem let us consider definitions of both \n",
    "diseases given by medics. Acute inflammation of urinary bladder is\n",
    "characterised by sudden occurrence of pains in the abdomen region and \n",
    "the urination in form of constant urine pushing, micturition pains and \n",
    "sometimes lack of urine keeping. Temperature of the body is rising, \n",
    "however most often not above 38C. The excreted urine is turbid and \n",
    "sometimes bloody. At proper treatment, symptoms decay usually within \n",
    "several days. However, there is inclination to returns. At persons with \n",
    "acute inflammation of urinary bladder, we should expect that the illness \n",
    "will turn into protracted form.\n",
    "\n",
    "Acute nephritis of renal pelvis origin occurs considerably more often at \n",
    "women than at men. It begins with sudden fever, which reaches, and \n",
    "sometimes exceeds 40C. The fever is accompanied by shivers and one- or \n",
    "both-side lumbar pains, which are sometimes very strong. Symptoms of \n",
    "acute inflammation of urinary bladder appear very often. Quite not \n",
    "infrequently there are nausea and vomiting and spread pains of whole \n",
    "abdomen.\n",
    "\n",
    "The data was created by a medical expert as a data set to test the \n",
    "expert system, which will perform the presumptive diagnosis of two \n",
    "diseases of urinary system. The basis for rules detection was Rough Sets \n",
    "Theory. Each instance represents an potential patient.\n",
    "\n",
    "The data is in an ASCII file. Attributes are separated by TAB. Each line \n",
    "of the data file starts with a digit which tells the temperature of patient.\n",
    "\n",
    "-- Attribute lines:<br/>\n",
    "For example, '35,9 no no yes yes yes yes no'<br/>\n",
    "Where:<br/>\n",
    "'35,9' Temperature of patient<br/>\n",
    "'no' Occurrence of nausea<br/>\n",
    "'no' Lumbar pain<br/>\n",
    "'yes' Urine pushing (continuous need for urination)<br/>\n",
    "'yes' Micturition pains<br/>\n",
    "'yes' Burning of urethra, itch, swelling of urethra outlet<br/>\n",
    "'yes' decision: Inflammation of urinary bladder<br/>\n",
    "'no' decision: Nephritis of renal pelvis origin<br/>\n",
    "\n",
    "----------------------------------------------------------------------------\n",
    "\n",
    "## Attribute Information:\n",
    "\n",
    "a1 Temperature of patient { 35C-42C }<br/>\n",
    "a2 Occurrence of nausea { yes, no }<br/>\n",
    "a3 Lumbar pain { yes, no }<br/>\n",
    "a4 Urine pushing (continuous need for urination) { yes, no }<br/>\n",
    "a5 Micturition pains { yes, no }<br/>\n",
    "a6 Burning of urethra, itch, swelling of urethra outlet { yes, no }<br/>\n",
    "d1 decision: Inflammation of urinary bladder { yes, no }<br/>\n",
    "d2 decision: Nephritis of renal pelvis origin { yes, no } <br/>\n",
    "\n",
    "----------------------------------------------------------------------------\n",
    "\n",
    "## Relevant Papers:\n",
    "\n",
    "J.Czerniak, H.Zarzycki, Application of rough sets in the presumptive \n",
    "diagnosis of urinary system diseases, Artifical Inteligence and Security \n",
    "in Computing Systems, ACS'2002 9th International Conference Proceedings, \n",
    "Kluwer Academic Publishers,2003, pp. 41-51\n",
    "\n",
    "----------------------------------------------------------------------------\n",
    "\n",
    "## Citation Request:\n",
    "\n",
    "Please cite:\n",
    "\n",
    "J.Czerniak, H.Zarzycki, Application of rough sets in the presumptive \n",
    "diagnosis of urinary system diseases, Artifical Inteligence and Security \n",
    "in Computing Systems, ACS'2002 9th International Conference Proceedings, \n",
    "Kluwer Academic Publishers,2003, pp. 41-51 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "def download_url(url, save_as):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read()\n",
    "    file = open(save_as, 'wb')\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "    response.close()\n",
    "    \n",
    "def read_binary_file(file):\n",
    "    f = open(file,'rb')\n",
    "    block = f.read()\n",
    "    return block.decode('utf-16')\n",
    "\n",
    "def split_text_in_lines(text):\n",
    "    return text.split('\\r\\n')\n",
    "\n",
    "def split_by_tabs(line):\n",
    "    return line.split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/acute/diagnosis.names'\n",
    "data_link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/acute/diagnosis.data'\n",
    "diagnosis_names = 'diagnosis.names'\n",
    "diagnosis_data = 'diagnosis.data'\n",
    "download_url(names_link, diagnosis_names)\n",
    "download_url(data_link, diagnosis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Train. Shape: (96, 8)\n",
      "[[40.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [37.6  0.   0.   1.   1.   0.   1.   0. ]\n",
      " [35.5  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [40.5  1.   1.   1.   1.   0.   1.   1. ]\n",
      " [37.3  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [40.   0.   1.   1.   0.   1.   0.   1. ]\n",
      " [41.1  1.   1.   1.   1.   0.   1.   1. ]\n",
      " [40.9  1.   1.   1.   1.   0.   1.   1. ]\n",
      " [41.1  1.   1.   0.   1.   0.   0.   1. ]\n",
      " [37.9  0.   0.   1.   1.   0.   1.   0. ]\n",
      " [36.2  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [36.8  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [41.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [40.2  1.   1.   1.   1.   1.   1.   1. ]\n",
      " [41.2  0.   0.   0.   0.   0.   0.   0. ]\n",
      " [36.6  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [37.3  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [39.   0.   1.   1.   0.   1.   0.   1. ]\n",
      " [38.   0.   1.   1.   0.   1.   0.   1. ]\n",
      " [41.5  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [37.   0.   0.   1.   1.   1.   1.   0. ]\n",
      " [40.7  1.   1.   0.   1.   0.   0.   1. ]\n",
      " [38.   0.   1.   1.   0.   1.   0.   1. ]\n",
      " [41.   0.   1.   1.   0.   1.   0.   1. ]\n",
      " [36.7  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [40.7  1.   1.   1.   1.   0.   1.   1. ]\n",
      " [37.   0.   0.   1.   0.   0.   1.   0. ]\n",
      " [41.1  1.   1.   1.   1.   1.   1.   1. ]\n",
      " [40.7  1.   1.   1.   1.   1.   1.   1. ]\n",
      " [37.5  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [36.6  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [37.1  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [37.9  0.   0.   1.   0.   0.   1.   0. ]\n",
      " [41.   1.   1.   0.   1.   0.   0.   1. ]\n",
      " [41.5  0.   0.   0.   0.   0.   0.   0. ]\n",
      " [41.4  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [36.7  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [41.2  1.   1.   1.   1.   1.   1.   1. ]\n",
      " [38.7  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [40.3  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [40.8  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [37.5  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [41.   1.   1.   1.   1.   1.   1.   1. ]\n",
      " [39.4  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [36.7  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [41.1  0.   0.   0.   0.   0.   0.   0. ]\n",
      " [40.9  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [41.1  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [40.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [38.9  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [37.   0.   0.   1.   1.   0.   1.   0. ]\n",
      " [40.9  1.   1.   1.   1.   0.   1.   1. ]\n",
      " [36.2  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [40.7  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [40.4  1.   1.   0.   1.   0.   0.   1. ]\n",
      " [36.3  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [40.4  0.   0.   0.   0.   0.   0.   0. ]\n",
      " [38.3  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [41.2  1.   1.   0.   1.   0.   0.   1. ]\n",
      " [37.   0.   0.   1.   1.   0.   1.   0. ]\n",
      " [36.9  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [40.   1.   1.   1.   1.   1.   1.   1. ]\n",
      " [41.5  1.   1.   0.   1.   0.   0.   1. ]\n",
      " [40.4  1.   1.   1.   1.   1.   1.   1. ]\n",
      " [40.4  1.   1.   1.   1.   0.   1.   1. ]\n",
      " [37.7  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [40.2  0.   0.   0.   0.   0.   0.   0. ]\n",
      " [37.2  0.   0.   1.   1.   0.   1.   0. ]\n",
      " [37.8  0.   0.   1.   0.   0.   1.   0. ]\n",
      " [36.6  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [40.6  0.   0.   0.   0.   0.   0.   0. ]\n",
      " [37.   0.   1.   0.   0.   0.   0.   0. ]\n",
      " [36.   0.   1.   0.   0.   0.   0.   0. ]\n",
      " [40.2  1.   1.   0.   1.   0.   0.   1. ]\n",
      " [37.7  0.   0.   1.   1.   0.   1.   0. ]\n",
      " [40.   1.   1.   0.   1.   0.   0.   1. ]\n",
      " [40.   1.   1.   0.   1.   0.   0.   1. ]\n",
      " [37.8  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [37.5  0.   0.   1.   0.   0.   1.   0. ]\n",
      " [37.3  0.   0.   1.   0.   0.   1.   0. ]\n",
      " [37.7  0.   0.   1.   1.   0.   1.   0. ]\n",
      " [41.2  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [38.5  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [35.9  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [37.9  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [40.7  0.   0.   0.   0.   0.   0.   0. ]\n",
      " [40.   1.   1.   1.   1.   0.   1.   1. ]\n",
      " [37.9  0.   0.   1.   1.   0.   1.   0. ]\n",
      " [37.6  0.   0.   1.   1.   0.   1.   0. ]\n",
      " [36.6  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [38.1  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [36.8  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [37.   0.   0.   1.   1.   1.   1.   0. ]\n",
      " [40.1  1.   1.   1.   1.   0.   1.   1. ]\n",
      " [39.7  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [36.   0.   1.   0.   0.   0.   0.   0. ]]\n",
      "Dataset Test. Shape: (24, 8)\n",
      "[[37.2  0.   0.   1.   0.   0.   1.   0. ]\n",
      " [35.9  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [40.6  1.   1.   1.   1.   1.   1.   1. ]\n",
      " [37.1  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [37.5  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [37.5  0.   0.   1.   0.   0.   1.   0. ]\n",
      " [36.9  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [41.5  0.   1.   1.   0.   1.   0.   1. ]\n",
      " [41.3  1.   1.   1.   1.   0.   1.   1. ]\n",
      " [40.4  1.   1.   1.   1.   0.   1.   1. ]\n",
      " [37.4  0.   0.   1.   0.   0.   1.   0. ]\n",
      " [36.   0.   0.   1.   1.   1.   1.   0. ]\n",
      " [40.   1.   1.   1.   1.   1.   1.   1. ]\n",
      " [37.   0.   0.   1.   1.   1.   1.   0. ]\n",
      " [37.2  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [37.7  0.   0.   1.   0.   0.   1.   0. ]\n",
      " [37.5  0.   0.   1.   1.   0.   1.   0. ]\n",
      " [40.6  1.   1.   0.   1.   0.   0.   1. ]\n",
      " [37.1  0.   0.   1.   0.   0.   1.   0. ]\n",
      " [37.   0.   0.   1.   1.   1.   1.   0. ]\n",
      " [37.9  0.   0.   1.   1.   1.   1.   0. ]\n",
      " [37.8  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [37.4  0.   1.   0.   0.   0.   0.   0. ]\n",
      " [37.6  0.   0.   1.   1.   1.   1.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_double(field):\n",
    "    field = field.replace(',', '.')\n",
    "    return float(field)\n",
    "\n",
    "def parse_boolean(field):\n",
    "    return 1. if field == 'yes' else 0.\n",
    "\n",
    "def read_np_array(file = diagnosis_data):\n",
    "    text = read_binary_file(file)\n",
    "    lines = split_text_in_lines(text)\n",
    "    rows = []\n",
    "    for line in lines:\n",
    "        if line == '': continue\n",
    "        line = line.replace('\\r\\n', '')\n",
    "        fields = split_by_tabs(line)\n",
    "        row = []\n",
    "        j = 0\n",
    "        for field in fields:\n",
    "            value = parse_double(field) if j == 0 else parse_boolean(field)\n",
    "            row.append(value)\n",
    "            j += 1\n",
    "        rows.append(row)\n",
    "    matrix = np.array(rows, dtype = np.float32)\n",
    "    return matrix\n",
    "\n",
    "def get_random_indexes(n):\n",
    "    indexes = list(range(n))\n",
    "    random_indexes = []\n",
    "    for i in range(n):\n",
    "        r = np.random.randint(len(indexes))\n",
    "        random_indexes.append(indexes.pop(r))\n",
    "    return random_indexes\n",
    "\n",
    "def get_indexes_for_2_datasets(n, training = 80):\n",
    "    indexes = get_random_indexes(n)\n",
    "    train = int(training / 100. * n)\n",
    "    return indexes[:train], indexes[train:]\n",
    "\n",
    "matrix = read_np_array()\n",
    "n_samples, n_dimensions = matrix.shape\n",
    "\n",
    "train_indexes, test_indexes = get_indexes_for_2_datasets(n_samples)\n",
    "train_data = matrix[train_indexes]\n",
    "test_data = matrix[test_indexes]\n",
    "\n",
    "def print_dataset(name, data):\n",
    "    print('Dataset {}. Shape: {}'.format(name, data.shape))\n",
    "    print(data)\n",
    "\n",
    "print_dataset('Train', train_data)\n",
    "print_dataset('Test', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(\n",
      "  (linear): Linear(in_features=6, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e3324ce24e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/private_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/private_pytorch/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 942\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/private_pytorch/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/private_pytorch/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1869\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1871\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1872\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'target'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_size = 6\n",
    "num_classes = 1\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes) #, dtype = torch.float64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)\n",
    "print(model)\n",
    "\n",
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "# Set parameters to be updated.\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "n_samples, _ = train_data.shape\n",
    "for epoch in range(num_epochs):\n",
    "    #for i in range(n_samples):\n",
    "        input = Variable(torch.tensor(train_data[:, :6], dtype = torch.float32))\n",
    "        output = Variable(torch.tensor(train_data[:, 6], dtype = torch.float32))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(input)\n",
    "        loss = criterion(prediction, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if (i+1) % 10 == 0:\n",
    "        print('loss={}'.format(loss.data[0]))\n",
    "            #print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "\n",
    "\"\"\"\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "                   % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "input = torch.tensor(train_data[:, :6], requires_grad = True)\n",
    "target = torch.tensor(train_data[:, 6], requires_grad = True)\n",
    "#weights = torch.tensor([[0.] for i in range(6)], dtype = torch.float64, requires_grad = True)\n",
    "#biases = torch.tensor([[0.] for i in range(6)], dtype = torch.float64, requires_grad = True)\n",
    "weights = np.zeros((6, 1), dtype = np.float64)\n",
    "weights = torch.tensor(weights, requires_grad = True)\n",
    "\n",
    "#biases = np.zeros((6, 1), dtype = np.float64)\n",
    "biases = torch.tensor(0., dtype = torch.float64, requires_grad = True)\n",
    "\n",
    "#biases = torch.tensor([0. for i in range(6)], dtype = torch.float64, requires_grad = True)\n",
    "\n",
    "print(input.dtype, target.dtype, weights.dtype, biases.dtype)\n",
    "print(input.shape, target.shape, weights.shape, biases.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    pred = input.mm(weights) + biases\n",
    "    loss = ((pred - target) ** 2).sum()\n",
    "    loss.backward()\n",
    "    weights.data.sub_(weights.grad * 0.1)\n",
    "    weights.grad *= 0\n",
    "    print(loss.data)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
